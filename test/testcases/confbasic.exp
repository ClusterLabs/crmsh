.TRY Basic configure
.INP: configure
.INP: _regtest on
.INP: erase
.INP: erase nodes
.INP: node node1
.INP: delete node1
.INP: node node1 	attributes mem=16G
.INP: node node2 utilization cpu=4
.INP: primitive st stonith:ssh 	params hostlist='node1 node2' 	meta target-role="Started" 	op start timeout=60s 	op monitor interval=60m timeout=60s
.EXT crm_resource --show-metadata stonith:ssh
.EXT stonithd metadata
.INP: primitive st2 stonith:ssh 	params hostlist='node1 node2'
.INP: primitive d1 ocf:pacemaker:Dummy 	operations $id=d1-ops 	op monitor interval=60m 	op monitor interval=120m OCF_CHECK_LEVEL=10
.EXT crm_resource --show-metadata ocf:pacemaker:Dummy
.INP: monitor d1 60s:30s
.INP: primitive d2 ocf:heartbeat:Delay 	params mondelay=60 	op start timeout=60s 	op stop timeout=60s
.EXT crm_resource --show-metadata ocf:heartbeat:Delay
.INP: monitor d2:Started 60s:30s
.INP: group g1 d1 d2
.INP: primitive d3 ocf:pacemaker:Dummy
.INP: clone c d3 	meta clone-max=1
.INP: primitive d4 ocf:pacemaker:Dummy
.INP: clone m d4 meta promotable=true
.INP: primitive s5 ocf:pacemaker:Stateful 	operations $id-ref=d1-ops
.EXT crm_resource --show-metadata ocf:pacemaker:Stateful
.INP: primitive s6 ocf:pacemaker:Stateful 	operations $id-ref=d1
.INP: clone m5 s5 meta promotable=true
.INP: clone m6 s6 meta promotable=true
.INP: primitive d7 Dummy 	params rule inf: #uname eq node1 fake=1 	params rule inf: #uname eq node2 fake=2         op start interval=0 timeout=60s         op_params 2: rule #uname eq node1 op_param=dummy         op_params 1: op_param=smart         op_meta 2: rule #ra-version version:gt 1.0 start-delay=120m         op_meta 1: start-delay=60m
.EXT crm_resource --show-metadata ocf:heartbeat:Dummy
.INP: primitive d8 ocf:pacemaker:Dummy
.INP: clone m7 d8 	meta promotable=true 	meta promoted-max=1 	meta promoted-node-max=1
.INP: location l1 g1 100: node1
.INP: location l2 c 	rule $id=l2-rule1 100: #uname eq node1
.INP: location l3 m5 	rule inf: #uname eq node1 and pingd gt 0
.INP: location l4 m5 	rule -inf: not_defined pingd or pingd lte 0
.INP: location l5 m5 	rule -inf: not_defined pingd or pingd lte 0
.INP: location l8 m5 	rule inf: #uname eq node1 and         pingd gt 0 and 	date lt "2009-05-26" and 	date in start="2009-05-26" end="2009-07-26" and 	date in start="2009-05-26" years="2009" and 	date spec years="2009" hours="09-17"
.INP: location l6 m5 	rule $id-ref=l2-rule1
.INP: location l7 m5 	rule $id-ref=l2
.INP: colocation c1 inf: m6 m5
.INP: colocation c2 inf: m5:Promoted g1:Started
.INP: order o1 Mandatory: m5 m6
.INP: order o2 Optional: g1:start m5:promote
.INP: order o3 Serialize: m5 m6
.INP: order o4 Mandatory: m5 m6
.INP: rsc_ticket ticket-A_m6 ticket-A: m6
.INP: rsc_ticket ticket-B_m6_m5 ticket-B: m6 m5 loss-policy=fence
.INP: rsc_ticket ticket-C_master ticket-C: m6 m5:Promoted loss-policy=fence
.INP: fencing_topology st st2
.INP: property stonith-enabled=true
.INP: property $id=cpset2 maintenance-mode=true
.INP: rsc_defaults failure-timeout=10m
.INP: op_defaults $id=opsdef2 rule 100: #uname eq node1 record-pending=true
.INP: tag t1: m5 m6
.INP: set d2.mondelay 45
.INP: _test
.INP: verify
.EXT crm_resource --list-options=primitive --all --output-as=xml
.EXT crm_attribute --list-options=cluster --all --output-as=xml
.INP: show
node node1 \
	attributes mem=16G
node node2 \
	utilization cpu=4
primitive d1 ocf:pacemaker:Dummy \
	operations $id=d1-ops \
	op monitor interval=60m timeout=20s \
	op monitor interval=120m timeout=20s \
	op_params OCF_CHECK_LEVEL=10 \
	op start timeout=20s interval=0s \
	op stop timeout=20s interval=0s \
	op monitor interval=60s timeout=30s
primitive d2 Delay \
	params mondelay=45 \
	op start timeout=60s interval=0s \
	op stop timeout=60s interval=0s \
	op monitor timeout=40s interval=10s \
	op monitor role=Started interval=60s timeout=30s
primitive d3 ocf:pacemaker:Dummy \
	op monitor timeout=20s interval=10s \
	op start timeout=20s interval=0s \
	op stop timeout=20s interval=0s
primitive d4 ocf:pacemaker:Dummy \
	op monitor timeout=20s interval=10s \
	op start timeout=20s interval=0s \
	op stop timeout=20s interval=0s
primitive d7 Dummy \
	params rule #uname eq node1 fake=1 \
	params rule #uname eq node2 fake=2 \
	op start interval=0s timeout=60s \
	op_params 2: rule #uname eq node1 op_param=dummy \
	op_params 1: op_param=smart \
	op_meta 2: rule #ra-version version:gt 1.0 start-delay=120m \
	op_meta 1: start-delay=60m \
	op monitor timeout=20s interval=10s \
	op stop timeout=20s interval=0s
primitive d8 ocf:pacemaker:Dummy \
	op monitor timeout=20s interval=10s \
	op start timeout=20s interval=0s \
	op stop timeout=20s interval=0s
primitive s5 ocf:pacemaker:Stateful \
	operations  $id-ref=d1-ops \
	op monitor timeout=20s interval=10s role=Promoted \
	op monitor timeout=20s interval=11s role=Unpromoted \
	op start timeout=20s interval=0s \
	op stop timeout=20s interval=0s \
        op promote timeout=10s interval=0s \
        op demote timeout=10s interval=0s
primitive s6 ocf:pacemaker:Stateful \
	operations  $id-ref=d1-ops \
	op monitor timeout=20s interval=10s role=Promoted \
	op monitor timeout=20s interval=11s role=Unpromoted \
	op start timeout=20s interval=0s \
	op stop timeout=20s interval=0s \
        op promote timeout=10s interval=0s \
        op demote timeout=10s interval=0s
primitive st stonith:ssh \
	params hostlist="node1 node2" \
	meta target-role=Started \
	op start timeout=60s interval=0s \
	op monitor interval=60m timeout=60s \
	op stop timeout=15s interval=0s
primitive st2 stonith:ssh \
	params hostlist="node1 node2" \
	op monitor timeout=20s interval=3600s \
	op start timeout=20s interval=0s \
	op stop timeout=15s interval=0s
group g1 d1 d2
clone c d3 \
	meta clone-max=1 interleave=true
clone m d4 \
	meta promotable=true interleave=true
clone m5 s5 \
	meta promotable=true interleave=true
clone m6 s6 \
	meta promotable=true interleave=true
clone m7 d8 \
	meta promotable=true interleave=true \
	meta promoted-max=1 \
	meta promoted-node-max=1
tag t1 m5 m6
colocation c1 inf: m6 m5
colocation c2 inf: m5:Promoted g1:Started
location l1 g1 100: node1
location l2 c \
	rule $id=l2-rule1 100: #uname eq node1
location l3 m5 \
	rule #uname eq node1 and pingd gt 0
location l4 m5 \
	rule -inf: not_defined pingd or pingd lte 0
location l5 m5 \
	rule -inf: not_defined pingd or pingd lte 0
location l6 m5 \
	rule $id-ref=l2-rule1
location l7 m5 \
	rule $id-ref=l2-rule1
location l8 m5 \
	rule #uname eq node1 and pingd gt 0 and date lt 2009-05-26 and date in start=2009-05-26 end=2009-07-26 and date in start=2009-05-26 years=2009 and date spec years=2009 hours=09-17
order o1 Mandatory: m5 m6
order o2 Optional: g1:start m5:promote
order o3 Serialize: m5 m6
order o4 Mandatory: m5 m6
fencing_topology st st2
rsc_ticket ticket-A_m6 ticket-A: m6
rsc_ticket ticket-B_m6_m5 ticket-B: m6 m5 loss-policy=fence
rsc_ticket ticket-C_master ticket-C: m6 m5:Promoted loss-policy=fence
property cib-bootstrap-options: \
	stonith-enabled=true
property cpset2: \
	maintenance-mode=true
rsc_defaults rsc-options: \
	failure-timeout=10m
op_defaults opsdef2: \
	rule 100: #uname eq node1 \
	record-pending=true
.INP: commit
.TRY -F node maintenance node1
.TRY -F resource maintenance g1 off
.TRY -F resource maintenance d1
.TRY -F configure property maintenance-mode=true
INFO: 'maintenance' attribute already exists in d1. Remove it? [YES]
INFO: 'maintenance' attribute already exists in g1. Remove it? [YES]
INFO: 'maintenance' attribute already exists in node1. Remove it? [YES]
.EXT crm_attribute --list-options=cluster --all --output-as=xml
