.TRY Basic configure
.INP: configure
.INP: _regtest on
.INP: erase
.INP: erase nodes
.INP: node node1
.INP: delete node1
.INP: node node1 	attributes mem=16G
.INP: node node2 utilization cpu=4
.INP: primitive st stonith:ssh 	params hostlist='node1 node2' 	meta target-role="Started" 	op start requires=nothing timeout=60s 	op monitor interval=60m timeout=60s
.INP: primitive st2 stonith:ssh 	params hostlist='node1 node2'
.INP: primitive d1 ocf:pacemaker:Dummy 	operations $id=d1-ops 	op monitor interval=60m 	op monitor interval=120m OCF_CHECK_LEVEL=10
.INP: monitor d1 60s:30s
.INP: primitive d2 ocf:heartbeat:Delay 	params mondelay=60 	op start timeout=60s 	op stop timeout=60s
.INP: monitor d2:Started 60s:30s
.INP: group g1 d1 d2
.INP: primitive d3 ocf:pacemaker:Dummy
.INP: clone c d3 	meta clone-max=1
.INP: primitive d4 ocf:pacemaker:Dummy
.INP: ms m d4
.INP: delete m
.INP: master m d4
.INP: primitive s5 ocf:pacemaker:Stateful 	operations $id-ref=d1-ops
.INP: primitive s6 ocf:pacemaker:Stateful 	operations $id-ref=d1
.INP: ms m5 s5
.INP: ms m6 s6
.INP: primitive d7 Dummy 	params rule inf: #uname eq node1 fake=1 	params rule inf: #uname eq node2 fake=2
.INP: location l1 g1 100: node1
.INP: location l2 c 	rule $id=l2-rule1 100: #uname eq node1
.INP: location l3 m5 	rule inf: #uname eq node1 and pingd gt 0
.INP: location l4 m5 	rule -inf: not_defined pingd or pingd lte 0
.INP: location l5 m5 	rule -inf: not_defined pingd or pingd lte 0 	rule inf: #uname eq node1 and pingd gt 0 	rule inf: date lt "2009-05-26" and 		date in start="2009-05-26" end="2009-07-26" and 		date in start="2009-05-26" years="2009" and 		date spec years="2009" hours="09-17"
.INP: location l6 m5 	rule $id-ref=l2-rule1
.INP: location l7 m5 	rule $id-ref=l2
.INP: collocation c1 inf: m6 m5
.INP: collocation c2 inf: m5:Master d1:Started
.INP: order o1 Mandatory: m5 m6
.INP: order o2 Optional: d1:start m5:promote
.INP: order o3 Serialize: m5 m6
.INP: order o4 inf: m5 m6
.INP: rsc_ticket ticket-A_m6 ticket-A: m6
.INP: rsc_ticket ticket-B_m6_m5 ticket-B: m6 m5 loss-policy=fence
.INP: rsc_ticket ticket-C_master ticket-C: m6 m5:Master loss-policy=fence
.INP: fencing_topology st st2
.INP: property stonith-enabled=true
.INP: property $id=cpset2 maintenance-mode=true
.INP: rsc_defaults failure-timeout=10m
.INP: op_defaults $id=opsdef2 rule 100: #uname eq node1 record-pending=true
.INP: tag t1: m5 m6
.INP: set d2.mondelay 45
.INP: _test
.INP: verify
.EXT crm_resource --show-metadata stonith:ssh
.EXT stonithd metadata
.EXT crm_resource --show-metadata ocf:pacemaker:Dummy
.EXT crm_resource --show-metadata ocf:heartbeat:Delay
.EXT crm_resource --show-metadata ocf:pacemaker:Stateful
.EXT crm_resource --show-metadata ocf:heartbeat:Dummy
WARNING: 51: c2: resource d1 is grouped, constraints should apply to the group
.EXT crmd metadata
.EXT pengine metadata
.EXT cib metadata
.INP: show
node node1 \
	attributes mem=16G
node node2 \
	utilization cpu=4
primitive d1 ocf:pacemaker:Dummy \
	operations $id=d1-ops \
	op monitor interval=60m \
	op monitor interval=120m \
	op_params OCF_CHECK_LEVEL=10 \
	op monitor interval=60s timeout=30s
primitive d2 Delay \
	params mondelay=45 \
	op start timeout=60s interval=0 \
	op stop timeout=60s interval=0 \
	op monitor role=Started interval=60s timeout=30s
primitive d3 ocf:pacemaker:Dummy
primitive d4 ocf:pacemaker:Dummy
primitive d7 Dummy \
	params rule #uname eq node1 fake=1 \
	params rule #uname eq node2 fake=2
primitive s5 ocf:pacemaker:Stateful \
	operations  $id-ref=d1-ops
primitive s6 ocf:pacemaker:Stateful \
	operations  $id-ref=d1-ops
primitive st stonith:ssh \
	params hostlist="node1 node2" \
	meta target-role=Started \
	op start requires=nothing timeout=60s interval=0 \
	op monitor interval=60m timeout=60s
primitive st2 stonith:ssh \
	params hostlist="node1 node2"
group g1 d1 d2
ms m d4
ms m5 s5
ms m6 s6
clone c d3 \
	meta clone-max=1
tag t1 m5 m6
colocation c1 inf: m6 m5
colocation c2 inf: m5:Master d1:Started
location l1 g1 100: node1
location l2 c \
	rule $id=l2-rule1 100: #uname eq node1
location l3 m5 \
	rule #uname eq node1 and pingd gt 0
location l4 m5 \
	rule -inf: not_defined pingd or pingd lte 0
location l5 m5 \
	rule -inf: not_defined pingd or pingd lte 0 \
	rule #uname eq node1 and pingd gt 0 \
	rule date lt 2009-05-26 and date in start=2009-05-26 end=2009-07-26 and date in start=2009-05-26 years=2009 and date spec years=2009 hours=09-17
location l6 m5 \
	rule $id-ref=l2-rule1
location l7 m5 \
	rule $id-ref=l2-rule1
order o1 Mandatory: m5 m6
order o2 Optional: d1:start m5:promote
order o3 Serialize: m5 m6
order o4 inf: m5 m6
fencing_topology st st2
rsc_ticket ticket-A_m6 ticket-A: m6
rsc_ticket ticket-B_m6_m5 ticket-B: m6 m5 loss-policy=fence
rsc_ticket ticket-C_master ticket-C: m6 m5:Master loss-policy=fence
property cib-bootstrap-options: \
	stonith-enabled=true
property cpset2: \
	maintenance-mode=true
rsc_defaults rsc-options: \
	failure-timeout=10m
op_defaults opsdef2: \
	rule 100: #uname eq node1 \
	record-pending=true
.INP: commit
WARNING: 53: c2: resource d1 is grouped, constraints should apply to the group
